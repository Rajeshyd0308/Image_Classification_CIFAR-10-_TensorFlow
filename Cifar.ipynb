{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image classification on CIFAR 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I am going to classify images from CIFAR 10 dataset which comprises of Trucks, Airplanes, Cars, Cats and so on.\n",
    "The image classifer developed is uses TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly we import libraries we are going to use later in the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\InstalledSoftwares\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step we import CIFAR10 dataset. Note: Keras is used only in this step, to import CIFAR10 dataset\n",
    ".We can also download the dataset from https://www.cs.toronto.edu/~kriz/cifar.html website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About CIFAR 10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: (50000, 32, 32, 3) (50000, 1)\n",
      "Test samples: (10000, 32, 32, 3) (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train samples:\", x_train.shape, y_train.shape)\n",
    "print(\"Test samples:\", x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. \n",
    "<br>\n",
    "The original data will be of form (50000, 3072)-for training set- you need to reshape the numpy arrays as (50000,32,32,3). But for us Keras has already done that job so we can directly start playing with the images.\n",
    "<br>\n",
    "The training images are present in x_train, they are 50000 and each of shape 32x32x3 (RGB images)\n",
    "The labels for those images are given in the array y_test, which is a row vector of shape (50000,1). Each row consists of a number from 0-9 representing one of the classes (Truck, airplane, ..)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22214da3588>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[2,:,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datapreprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to scale the input pixel values which are spread out between 0-255 to 0-1\n",
    "<br>\n",
    "Link for more elaborate explaination https://www.youtube.com/watch?v=FDCfw-YqWTE by Andrew Ng\n",
    "<br>\n",
    "This normalization step allows our features to be on same scale so,  thereby allowing our model to converge faster, instead of taking too many steps during optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_N = x_train/255\n",
    "x_test_N = x_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to convert Y to a one_hot vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(labels):\n",
    "    m = labels.shape[0]\n",
    "    num_classes = 10\n",
    "    zero_vector = np.zeros((m,num_classes))\n",
    "    for i in range(0,m):\n",
    "        zero_vector[i,labels[i]] = 1\n",
    "    return zero_vector\n",
    "y_train_H = one_hot(y_train)\n",
    "y_test_H = one_hot(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(y_train_H.shape)\n",
    "print(y_test_H.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates two placeholder X (for passing images) an edge in out TF graph and Y (labels of those corresponding images) another edge in our TF computation graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(n_H, n_W, n_C, n_y):\n",
    "    X = tf.placeholder(tf.float32, [None, n_H, n_W, n_C])\n",
    "    Y = tf.placeholder(tf.float32, [None, n_y])\n",
    "    #Here None denotes the number of input examples\n",
    "    # n_H, N_W, and n_C are image height, width and number of channels \n",
    "    # n_y is number of classes of images\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture of CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entire model of our conv-net follows conv->conv->pool structure that is every two conv layers are follwed by a pooling layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input image fed into the CNN is first fed in to\n",
    "<br>\n",
    "1. Convolution layer comprising of 3x3x3 filters, 16 in number followed by Relu activation.\n",
    "<br>\n",
    "2. Convolution layer comprising of 3x3x3 filters, 32 in number followed by Relu activation.\n",
    "<br>\n",
    "3. Max pooling by 2x2 filters with stride 2\n",
    "    * Dropout Layer\n",
    "    * Batch normalization layer\n",
    "<br>\n",
    "4. Convolution layer comprising of 3x3x3 filters, 32 in number followed by Relu activation.\n",
    "<br>\n",
    "5. Convolution layer comprising of 3x3x3 filters, 64 in number followed by Relu activation.\n",
    "<br>\n",
    "6. Max pooling by 2x2 filters with stride 2\n",
    "    * Dropout Layer\n",
    "    * Batch normalization layer\n",
    "<br>\n",
    "7. Flattening 3D output of the previous layer \n",
    "<br>\n",
    "8. Fully connected layer of 256 units followed by Relu activation\n",
    "    * Dropout Layer\n",
    "<br>\n",
    "9. Fully connected layer of 10 units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly we initialize our filters, these are tensor flow variables as they are subjected to change while training\n",
    "<br>\n",
    "We use Xavier initialization to initialize our filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_initialize():\n",
    "    w1 = tf.get_variable(\"w1\", [3, 3, 3, 16], initializer =tf.contrib.layers.xavier_initializer())\n",
    "    w2 = tf.get_variable(\"w2\", [3, 3, 16, 32], initializer =tf.contrib.layers.xavier_initializer())\n",
    "    w3 = tf.get_variable(\"w3\", [3, 3, 32, 32], initializer =tf.contrib.layers.xavier_initializer())\n",
    "    w4 = tf.get_variable(\"w4\", [3, 3, 32, 64], initializer =tf.contrib.layers.xavier_initializer())\n",
    "    param = {\"w1\": w1, \"w2\": w2, \"w3\": w3, \"w4\": w4}\n",
    "    return param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Propagation\n",
    "All the convolution filters use SAME padding so the height and width of the image or previous layer output remain unchanged.\n",
    "<br>\n",
    "We use max pooling layer with Valid padding so the height and width of previous layer become half - due use of 2x2 filters-.\n",
    "<br>\n",
    "keep_prob_cnn and keep_prob_fully_connected are drop out probabilities of convolution layers and fully connected layer respectivelty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, params, keep_prob_cnn, keep_prob_fully_connected):\n",
    "    w1 = params[\"w1\"]\n",
    "    w2 = params[\"w2\"]\n",
    "    w3 = params[\"w3\"]\n",
    "    w4 = params[\"w4\"]\n",
    "    #l1\n",
    "    z1 = tf.nn.conv2d(X, w1, strides = [1,1,1,1], padding = 'SAME')\n",
    "    a1 = tf.nn.relu(z1)\n",
    "    #l2\n",
    "    z2 = tf.nn.conv2d(a1, w2, strides = [1,1,1,1], padding = 'SAME')\n",
    "    a2 = tf.nn.relu(z2)\n",
    "    p2 = tf.nn.max_pool(a2, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'VALID')\n",
    "    drop1 = tf.nn.dropout(p2, keep_prob_cnn)\n",
    "    b2 = tf.layers.batch_normalization(drop1)\n",
    "    #l3\n",
    "    z3 = tf.nn.conv2d(b2, w3, strides = [1,1,1,1], padding = 'SAME')\n",
    "    a3 = tf.nn.relu(z3)\n",
    "    #l4\n",
    "    z4 = tf.nn.conv2d(a3, w4, strides = [1,1,1,1], padding = 'SAME')\n",
    "    a4 = tf.nn.relu(z4)\n",
    "    p4 = tf.nn.max_pool(a4, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'VALID')\n",
    "    drop2 = tf.nn.dropout(p4, keep_prob_cnn)\n",
    "    b4 = tf.layers.batch_normalization(p4)\n",
    "    #fully connected\n",
    "    flat = tf.contrib.layers.flatten(b4)\n",
    "    a5 = tf.contrib.layers.fully_connected(flat, 256, activation_fn=tf.nn.relu)\n",
    "    drop3 = tf.nn.dropout(a5, keep_prob_fully_connected)\n",
    "    a6 = tf.contrib.layers.fully_connected(drop3, 10, activation_fn=None)\n",
    "    return a6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The softmax loss:\n",
    "<br>\n",
    "Here a6 is the output of forward propagation(unscaled)\n",
    "<br>\n",
    "Y is the true lanbel (one_hot vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(a6, Y):\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = a6, labels = Y))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to memory constarints we divide our 50000 training examples into batches of 64 (Total of ~782 batches)\n",
    "<br>\n",
    "Number of batches are determined by floor(m/MiniBatchSize) \n",
    "<br>\n",
    "The last batch will be comprised f remaining examples (m - NumberOfMiniBatches*ExamplesPerMinibatch)\n",
    "<br>\n",
    "At each instant minibatches are samples randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_minbatches(X, Y, mini_batchsize = 64):\n",
    "    m = X.shape[0]\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffle_X = X[permutation, :,:,:]\n",
    "    shuffle_Y = Y[permutation, :]\n",
    "    \n",
    "    minibatches = []\n",
    "    num_minibatches = math.floor(m/mini_batchsize)\n",
    "    for i in range(0, num_minibatches):\n",
    "        mini_X = shuffle_X[i*mini_batchsize: (i+1)*mini_batchsize, :, :, :]\n",
    "        mini_Y = shuffle_Y[i*mini_batchsize: (i+1)*mini_batchsize, :]\n",
    "        minibatch = (mini_X, mini_Y)\n",
    "        minibatches.append(minibatch)\n",
    "    if m%mini_batchsize !=0\n",
    "        mini_X = shuffle_X[mini_batchsize*num_minibatches: m, :, :, :]\n",
    "        mini_Y = shuffle_Y[mini_batchsize*num_minibatches: m, :]\n",
    "        minibatch = (mini_X, mini_Y)\n",
    "        minibatches.append(minibatch)\n",
    "    return minibatches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Model\n",
    "I used AdamOptimizer as our update rule (GD or MU can be used but they are slow when comapared to adam)\n",
    "<br>\n",
    "For every 200 minibatches we print the cost and training accuracy just to keep track of our progress instead of waiting for 1 epoch\n",
    "<br>\n",
    "Learning Rate is 0.002 and the training continues for 10 epochs\n",
    "<br>\n",
    "After training is done we check the accuracy of our model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x_train, y_train, x_test, y_test):\n",
    "    \n",
    "    ops.reset_default_graph() # when we rerun graph does not start from previous point\n",
    "    lr = 0.002\n",
    "    minibatch_size = 64\n",
    "    keep_prob_cnn = 0.25\n",
    "    keep_prob_fully_connected = 0.5\n",
    "    \n",
    "    (m, n_H, n_W, n_C) = x_train.shape\n",
    "    n_y = y_train.shape[1]\n",
    "    X, Y = create_placeholders(n_H, n_W, n_C, n_y)\n",
    "    \n",
    "    parameters = random_initialize()\n",
    "    \n",
    "    out = forward_propagation(X, parameters, keep_prob_cn, keep_prob_fully_connectedn)\n",
    "    \n",
    "    cost = cost_function(out, Y)\n",
    "    loss = []\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = lr).minimize(cost)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        sess.run(init)\n",
    "        \n",
    "        num_mini = int(m/minibatch_size)\n",
    "        \n",
    "        for epoch in range(0,10):\n",
    "            \n",
    "            minibatches = create_minbatches(x_train, y_train, mini_batchsize = 64)\n",
    "            loss_ep = 0\n",
    "            k=0\n",
    "            \n",
    "            for minibatch in minibatches:\n",
    "                (mini_X, mini_Y) = minibatch\n",
    "                _ , temp_cost = sess.run([optimizer,cost], feed_dict={X: mini_X, Y: mini_Y})\n",
    "                loss_ep += temp_cost/num_mini\n",
    "                if k%200 ==0:\n",
    "                    print(\"The cost after \"+str(k+1)+ \" minibatches in  epoch \"+ str(epoch)+\" is \"+str(temp_cost))\n",
    "                    prediction = tf.argmax(out, 1)\n",
    "                    p_equal = tf.equal(prediction, tf.argmax(Y, 1))\n",
    "                    accuracy = tf.reduce_mean(tf.cast(p_equal, \"float\"))\n",
    "                    train_accuracy = accuracy.eval({X: mini_X, Y: mini_Y})\n",
    "                    print(\"The train accuracy is \"+str(train_accuracy))\n",
    "                k+=1\n",
    "                \n",
    "            loss.append(loss_ep)\n",
    "            print(\"Total Loss\"+ str(loss_ep))\n",
    "        \n",
    "        keep_prob_cnn = 1\n",
    "        keep_prob_fully_connected = 1\n",
    "        out1 = forward_propagation(X, parameters, keep_prob_cn, keep_prob_fully_connectedn)\n",
    "        prediction = tf.argmax(out1, 1)\n",
    "        p_equal = tf.equal(prediction, tf.argmax(Y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(p_equal, \"float\"))\n",
    "        test_accuracy = accuracy.eval({X: x_test[0:100,:,:,:], Y: y_test[0:100,:]})\n",
    "        print(\"The test set accuracy is \"+str(test_accuracy))\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-c28ec87f4f6a>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "The cost after 1 minibatches in  epoch 0 is 2.2931511\n",
      "The train accuracy is 0.15625\n",
      "The cost after 201 minibatches in  epoch 0 is 1.7663238\n",
      "The train accuracy is 0.328125\n",
      "The cost after 401 minibatches in  epoch 0 is 1.5289774\n",
      "The train accuracy is 0.484375\n",
      "The cost after 601 minibatches in  epoch 0 is 1.5111376\n",
      "The train accuracy is 0.421875\n",
      "Total Loss1.6276597622567321\n",
      "The cost after 1 minibatches in  epoch 1 is 1.4455782\n",
      "The train accuracy is 0.484375\n",
      "The cost after 201 minibatches in  epoch 1 is 1.3074039\n",
      "The train accuracy is 0.5625\n",
      "The cost after 401 minibatches in  epoch 1 is 1.4768271\n",
      "The train accuracy is 0.53125\n",
      "The cost after 601 minibatches in  epoch 1 is 1.2815166\n",
      "The train accuracy is 0.46875\n",
      "Total Loss1.2892301039109613\n",
      "The cost after 1 minibatches in  epoch 2 is 1.3946996\n",
      "The train accuracy is 0.53125\n",
      "The cost after 201 minibatches in  epoch 2 is 1.244775\n",
      "The train accuracy is 0.59375\n",
      "The cost after 401 minibatches in  epoch 2 is 1.0275781\n",
      "The train accuracy is 0.65625\n",
      "The cost after 601 minibatches in  epoch 2 is 1.2355138\n",
      "The train accuracy is 0.578125\n",
      "Total Loss1.1874182720343083\n",
      "The cost after 1 minibatches in  epoch 3 is 1.1002765\n",
      "The train accuracy is 0.625\n",
      "The cost after 201 minibatches in  epoch 3 is 1.1077728\n",
      "The train accuracy is 0.578125\n",
      "The cost after 401 minibatches in  epoch 3 is 0.922515\n",
      "The train accuracy is 0.671875\n",
      "The cost after 601 minibatches in  epoch 3 is 1.1149739\n",
      "The train accuracy is 0.625\n",
      "Total Loss1.125867065638495\n",
      "The cost after 1 minibatches in  epoch 4 is 1.398325\n",
      "The train accuracy is 0.53125\n",
      "The cost after 201 minibatches in  epoch 4 is 1.1261884\n",
      "The train accuracy is 0.578125\n",
      "The cost after 401 minibatches in  epoch 4 is 0.91223633\n",
      "The train accuracy is 0.65625\n",
      "The cost after 601 minibatches in  epoch 4 is 1.1181521\n",
      "The train accuracy is 0.578125\n",
      "Total Loss1.0701113688197834\n",
      "The cost after 1 minibatches in  epoch 5 is 1.0530086\n",
      "The train accuracy is 0.65625\n",
      "The cost after 201 minibatches in  epoch 5 is 0.97689205\n",
      "The train accuracy is 0.71875\n",
      "The cost after 401 minibatches in  epoch 5 is 0.7945755\n",
      "The train accuracy is 0.703125\n",
      "The cost after 601 minibatches in  epoch 5 is 0.8720493\n",
      "The train accuracy is 0.734375\n",
      "Total Loss1.0271598684497738\n",
      "The cost after 1 minibatches in  epoch 6 is 0.8744527\n",
      "The train accuracy is 0.71875\n",
      "The cost after 201 minibatches in  epoch 6 is 0.8669772\n",
      "The train accuracy is 0.6875\n",
      "The cost after 401 minibatches in  epoch 6 is 0.99393225\n",
      "The train accuracy is 0.671875\n",
      "The cost after 601 minibatches in  epoch 6 is 0.95706177\n",
      "The train accuracy is 0.671875\n",
      "Total Loss0.9933594636972064\n",
      "The cost after 1 minibatches in  epoch 7 is 1.1719875\n",
      "The train accuracy is 0.609375\n",
      "The cost after 201 minibatches in  epoch 7 is 0.8461392\n",
      "The train accuracy is 0.6875\n",
      "The cost after 401 minibatches in  epoch 7 is 1.0553069\n",
      "The train accuracy is 0.65625\n",
      "The cost after 601 minibatches in  epoch 7 is 0.9075029\n",
      "The train accuracy is 0.734375\n",
      "Total Loss0.9592992406953769\n",
      "The cost after 1 minibatches in  epoch 8 is 0.9349289\n",
      "The train accuracy is 0.6875\n",
      "The cost after 201 minibatches in  epoch 8 is 0.87762797\n",
      "The train accuracy is 0.65625\n",
      "The cost after 401 minibatches in  epoch 8 is 0.94198984\n",
      "The train accuracy is 0.625\n",
      "The cost after 601 minibatches in  epoch 8 is 0.96628\n",
      "The train accuracy is 0.59375\n",
      "Total Loss0.9286040656087345\n",
      "The cost after 1 minibatches in  epoch 9 is 0.7525972\n",
      "The train accuracy is 0.703125\n",
      "The cost after 201 minibatches in  epoch 9 is 0.986826\n",
      "The train accuracy is 0.65625\n",
      "The cost after 401 minibatches in  epoch 9 is 0.6740058\n",
      "The train accuracy is 0.765625\n",
      "The cost after 601 minibatches in  epoch 9 is 1.0526111\n",
      "The train accuracy is 0.6875\n",
      "Total Loss0.9077750845083672\n",
      "The test set accuracy is 0.68\n"
     ]
    }
   ],
   "source": [
    "params = model(x_train_N, y_train_H, x_test_N, y_test_H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "So, finally the test accuracy was around 68%. As we can see that total loss was still decreasing significatly this test accuarcy can be improved by further continuing the training process .\n",
    "<br>\n",
    "Due to hardware constraints I stopped my training after 10 epochs (It took 7hrs to run 10 epochs on my i3 processor with 4Gb of RAM)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
